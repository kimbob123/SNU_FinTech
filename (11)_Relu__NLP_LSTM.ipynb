{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimbob123/SNU_FinTech/blob/main/(11)_Relu__NLP_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr5eMSTJYRd9"
      },
      "source": [
        "#시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd9zX_EX7wWm",
        "outputId": "96e4e3c7-767f-4cd0-bee9-8425ecc5c53b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb77r5TTy6i5",
        "outputId": "a724cabb-5613-4bd5-96be-d612cdb06b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "unrlEoIBy4Yn"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "import tqdm\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8Rio49-xiRP",
        "outputId": "f6fd1fb9-61ee-46c1-e8ae-9cba77feb56c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ipykernel==5.5.6\n",
            "ipython==7.34.0\n",
            "numpy==1.25.2\n",
            "pandas==2.0.3\n",
            "pytz==2023.4\n",
            "torch==2.3.0+cu121\n",
            "torchaudio==2.3.0+cu121\n",
            "torchtext==0.18.0\n",
            "torchvision==0.18.0+cu121\n",
            "tqdm==4.66.4\n"
          ]
        }
      ],
      "source": [
        "import pkg_resources\n",
        "\n",
        "# 확인할 패키지 리스트\n",
        "packages_to_check = [\n",
        "    \"datasets\",\n",
        "    \"ipykernel\",\n",
        "    \"ipython\",\n",
        "    \"numpy\",\n",
        "    \"pandas\",\n",
        "    \"pytz\",\n",
        "    \"torch\",\n",
        "    \"torchaudio\",\n",
        "    \"torchtext\",\n",
        "    \"torchvision\",\n",
        "    \"tqdm\"\n",
        "]\n",
        "\n",
        "# 설치된 패키지의 이름과 버전 출력\n",
        "installed_packages = pkg_resources.working_set\n",
        "for package in installed_packages:\n",
        "    if package.project_name in packages_to_check:\n",
        "        print(f\"{package.project_name}=={package.version}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HxiYLZArysG_"
      },
      "outputs": [],
      "source": [
        "seed = 1234\n",
        "\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9lM1F7jYTsq"
      },
      "source": [
        "#전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOoFIRmTLEOj",
        "outputId": "cf7fe06a-bfc9-491d-caba-c299ce1484aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIZT3dcf8Ups",
        "outputId": "734b973d-a925-4186-9fe2-9136bdd11422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 57477 entries, 0 to 57476\n",
            "Data columns (total 9 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   id              57477 non-null  int64 \n",
            " 1   model_a         57477 non-null  object\n",
            " 2   model_b         57477 non-null  object\n",
            " 3   prompt          57477 non-null  object\n",
            " 4   response_a      57477 non-null  object\n",
            " 5   response_b      57477 non-null  object\n",
            " 6   winner_model_a  57477 non-null  int64 \n",
            " 7   winner_model_b  57477 non-null  int64 \n",
            " 8   winner_tie      57477 non-null  int64 \n",
            "dtypes: int64(4), object(5)\n",
            "memory usage: 3.9+ MB\n"
          ]
        }
      ],
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/챗봇 답변 선호/train.csv')\n",
        "train_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "iirBqMdvusn3",
        "outputId": "2b02d388-6b9f-4a85-9814-0ded4389f19d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               id             model_a              model_b  \\\n",
              "0           30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1           53567           koala-13b           gpt-4-0613   \n",
              "2           65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3           96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4          198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "...           ...                 ...                  ...   \n",
              "57472  4294656694          gpt-4-0613             claude-1   \n",
              "57473  4294692063          claude-2.0     llama-2-13b-chat   \n",
              "57474  4294710549            claude-1           alpaca-13b   \n",
              "57475  4294899228              palm-2       tulu-2-dpo-70b   \n",
              "57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
              "\n",
              "                                                  prompt  \\\n",
              "0      [\"Is it morally right to try to have a certain...   \n",
              "1      [\"What is the difference between marriage lice...   \n",
              "2      [\"explain function calling. how would you call...   \n",
              "3      [\"How can I create a test set for a very rare ...   \n",
              "4      [\"What is the best way to travel from Tel-Aviv...   \n",
              "...                                                  ...   \n",
              "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
              "57473  [\"In python, implement a naive Bayes with gaus...   \n",
              "57474  [\"is it unethical to work on building weapons?...   \n",
              "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
              "57476  [\"three kids eat three apples in three days, h...   \n",
              "\n",
              "                                              response_a  \\\n",
              "0      [\"The question of whether it is morally right ...   \n",
              "1      [\"A marriage license is a legal document that ...   \n",
              "2      [\"Function calling is the process of invoking ...   \n",
              "3      [\"Creating a test set for a very rare category...   \n",
              "4      [\"The best way to travel from Tel Aviv to Jeru...   \n",
              "...                                                  ...   \n",
              "57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n",
              "57473  [\"Here is an implementation of a naive Bayes c...   \n",
              "57474  [\"Working on weapons technology raises some et...   \n",
              "57475  [\"Bromadiolone is a rodenticide which is most ...   \n",
              "57476                                      [\"27 apples\"]   \n",
              "\n",
              "                                              response_b  winner_model_a  \\\n",
              "0      [\"As an AI, I don't have personal beliefs or o...               1   \n",
              "1      [\"A marriage license and a marriage certificat...               0   \n",
              "2      [\"Function calling is the process of invoking ...               0   \n",
              "3      [\"When building a classifier for a very rare c...               1   \n",
              "4      [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
              "...                                                  ...             ...   \n",
              "57472  [\"Here is how that mnemonic represents the dig...               1   \n",
              "57473  [\"Sure! Here's an implementation of a naive Ba...               1   \n",
              "57474  [\"It depends on the context. Weapons can be us...               1   \n",
              "57475  [\"As an AI language model, I do not promote or...               0   \n",
              "57476  [\"If three kids eat three apples in three days...               1   \n",
              "\n",
              "       winner_model_b  winner_tie  \n",
              "0                   0           0  \n",
              "1                   1           0  \n",
              "2                   0           1  \n",
              "3                   0           0  \n",
              "4                   1           0  \n",
              "...               ...         ...  \n",
              "57472               0           0  \n",
              "57473               0           0  \n",
              "57474               0           0  \n",
              "57475               1           0  \n",
              "57476               0           0  \n",
              "\n",
              "[57477 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be7aceea-fe47-429d-8d81-894596395a67\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[\"Is it morally right to try to have a certain...</td>\n",
              "      <td>[\"The question of whether it is morally right ...</td>\n",
              "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[\"What is the difference between marriage lice...</td>\n",
              "      <td>[\"A marriage license is a legal document that ...</td>\n",
              "      <td>[\"A marriage license and a marriage certificat...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>[\"explain function calling. how would you call...</td>\n",
              "      <td>[\"Function calling is the process of invoking ...</td>\n",
              "      <td>[\"Function calling is the process of invoking ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>[\"How can I create a test set for a very rare ...</td>\n",
              "      <td>[\"Creating a test set for a very rare category...</td>\n",
              "      <td>[\"When building a classifier for a very rare c...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
              "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
              "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57472</th>\n",
              "      <td>4294656694</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>claude-1</td>\n",
              "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
              "      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n",
              "      <td>[\"Here is how that mnemonic represents the dig...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57473</th>\n",
              "      <td>4294692063</td>\n",
              "      <td>claude-2.0</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
              "      <td>[\"Here is an implementation of a naive Bayes c...</td>\n",
              "      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57474</th>\n",
              "      <td>4294710549</td>\n",
              "      <td>claude-1</td>\n",
              "      <td>alpaca-13b</td>\n",
              "      <td>[\"is it unethical to work on building weapons?...</td>\n",
              "      <td>[\"Working on weapons technology raises some et...</td>\n",
              "      <td>[\"It depends on the context. Weapons can be us...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57475</th>\n",
              "      <td>4294899228</td>\n",
              "      <td>palm-2</td>\n",
              "      <td>tulu-2-dpo-70b</td>\n",
              "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
              "      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n",
              "      <td>[\"As an AI language model, I do not promote or...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57476</th>\n",
              "      <td>4294947231</td>\n",
              "      <td>gemini-pro-dev-api</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>[\"three kids eat three apples in three days, h...</td>\n",
              "      <td>[\"27 apples\"]</td>\n",
              "      <td>[\"If three kids eat three apples in three days...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57477 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be7aceea-fe47-429d-8d81-894596395a67')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be7aceea-fe47-429d-8d81-894596395a67 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be7aceea-fe47-429d-8d81-894596395a67');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8ec0a8e5-485a-47ef-9854-25ac2478c5d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ec0a8e5-485a-47ef-9854-25ac2478c5d1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8ec0a8e5-485a-47ef-9854-25ac2478c5d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5b3a9020-6ecc-46f0-b7af-fc380ca39eba\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5b3a9020-6ecc-46f0-b7af-fc380ca39eba button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 57477,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1238326827,\n        \"min\": 30192,\n        \"max\": 4294947231,\n        \"num_unique_values\": 57477,\n        \"samples\": [\n          2785062085,\n          48259531,\n          3622731894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_a\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"mistral-7b-instruct\",\n          \"guanaco-33b\",\n          \"gpt-4-1106-preview\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_b\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"llama2-70b-steerlm-chat\",\n          \"llama-13b\",\n          \"gpt-4-0613\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 51734,\n        \"samples\": [\n          \"[\\\"Are autoregressive language models (e.g. GPT-3) currently more popular than auto-encoding language models (e.g. BERT)? If so, what are the explanations?\\\"]\",\n          \"[\\\"Write a c++ algorithm that aims to find the rightmost zero in a binary representation, flip it to a one, and flip any 1s to its right\\\"]\",\n          \"[\\\"What is J\\\\u00e9r\\\\u00f4me WAX ?\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_a\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56566,\n        \"samples\": [\n          \"[\\\"Tea is grown commercially in the Azores, an autonomous region of Portugal. The main tea-producing estates are located on the island of S\\\\u00e3o Miguel, where the only commercial tea plantations in Europe can be found. The most well-known tea estates on S\\\\u00e3o Miguel are Gorreana Tea Estate and Porto Formoso Tea Factory.\\\"]\",\n          \"[\\\"Sure! Here's an example to illustrate how function pointers work in C:\\\\n\\\\n```c\\\\n#include <stdio.h>\\\\n\\\\n\\\\/\\\\/ Function to be pointed to\\\\nint add(int a, int b) {\\\\n    return a + b;\\\\n}\\\\n\\\\n\\\\/\\\\/ Function to demonstrate function pointers\\\\nvoid functionPointerExample(int (*funcPtr)(int, int)) {\\\\n    int result = funcPtr(5, 10);\\\\n    printf(\\\\\\\"Result: %d\\\\\\\\n\\\\\\\", result);\\\\n}\\\\n\\\\nint main() {\\\\n    \\\\/\\\\/ Use the address-of operator (&) to get the address of the add function\\\\n    int (*addPtr)(int, int) = &add;\\\\n\\\\n    \\\\/\\\\/ Call the functionPointerExample function and pass the address of the add function\\\\n    functionPointerExample(addPtr);\\\\n\\\\n    \\\\/\\\\/ Call the add function directly\\\\n    int result = add(15, 20);\\\\n    printf(\\\\\\\"Result: %d\\\\\\\\n\\\\\\\", result);\\\\n\\\\n    return 0;\\\\n}\\\\n```\\\\n\\\\nIn this example, we define a function `add` that takes two integers as arguments and returns their sum.\\\\n\\\\nWe then define a function `functionPointerExample` that takes a function pointer as an argument. This function calls the pointed-to function passing it two integers, and then prints the result.\\\\n\\\\nIn the main function, we create a function pointer `addPtr` which points to the `add` function. We then call the `functionPointerExample` function passing the address of the `add` function using the `&` operator.\\\\n\\\\nFinally, we call the `add` function directly and store the result in a variable `result`.\\\\n\\\\nI hope this helps you understand how function pointers work in C! Let me know if you have any other questions.\\\",\\\"To define a function pointer within a struct, you can define a member variable of the struct as a pointer to a function with a specific return type and argument list. Here's an example:\\\\n\\\\n```c\\\\n#include <stdio.h>\\\\n\\\\n\\\\/\\\\/ Define a structure with a function pointer member\\\\ntypedef struct {\\\\n    int (*calculate)(int);\\\\n} Calculator;\\\\n\\\\n\\\\/\\\\/ Function to be pointed to\\\\nint add(int num) {\\\\n    return num + 10;\\\\n}\\\\n\\\\n\\\\/\\\\/ Function to demonstrate using a function pointer within a struct\\\\nvoid useCalculator(Calculator calculator) {\\\\n    int result = calculator.calculate(15);\\\\n    printf(\\\\\\\"Result: %d\\\\\\\\n\\\\\\\", result);\\\\n}\\\\n\\\\nint main() {\\\\n    \\\\/\\\\/ Create a Calculator struct and initialize the function pointer member\\\\n    Calculator calculator = { add };\\\\n\\\\n    \\\\/\\\\/ Call the useCalculator function and pass the calculator struct\\\\n    useCalculator(calculator);\\\\n\\\\n    return 0;\\\\n}\\\\n```\\\\n\\\\nIn this example, we define a `typedef` for our `Calculator` struct, which has a single member `calculate` that is a pointer to a function that takes an integer as an argument and returns an integer.\\\\n\\\\nWe then define a function `add` that adds 10 to the input integer and return the result.\\\\n\\\\nWe define a function `useCalculator` that takes a `Calculator` struct as an argument and invokes the `calculate` member function of the struct with an argument of 15.\\\\n\\\\nIn the `main` function, we create a `Calculator` struct and initialize its `calculate` member with the address of the `add` function. We then call the `useCalculator` function passing the `calculator` struct.\\\\n\\\\nI hope this helps you understand how to define a function pointer within a struct in C! Let me know if you have any other questions.\\\"]\",\n          \"[\\\"In the depths of a dark and mysterious cave, there lived a heavily pregnant cavewoman named Ula. Her thick, matted hair cascaded down her back, and her skin was tanned and rough from years of living in the harsh wilderness. Ula's husband, Kadan, was a skilled hunter and provided for their small tribe. But lately, even his sharpest arrows seemed to fall short, and food had become scarce.\\\\n\\\\nUla felt a deep ache in her bones and her swollen belly. It was the third trimester, and her baby was growing rapidly. She wondered if she would ever be able to give birth in the cramped, narrow cave. Ula's tribe had no midwife, and her only hope was to rely on the wisdom passed down from her own mother.\\\\n\\\\nOne day, while Kadan was out hunting, Ula went into labor. Her screams echoed through the cave, and her tribe gathered around her in a frenzy. Ula's eyes widened as she felt the intense pain of contractions. She was afraid for her baby's life and her own.\\\\n\\\\nThe tribe tried to comfort Ula, but their efforts fell short. Ula's baby was too big, and the birth seemed impossible. Hours passed, and Ula lost all strength. Her tribe watched in horror as Ula's life slipped away. Suddenly, a loud cry broke the silence. Ula's baby had been born, and he was healthy and strong.\\\\n\\\\nThe tribe rejoiced at the sight of the newborn. They named him Kade, after Ula's husband, Kadan. Kade was a symbol of hope and resilience, and his birth brought new life and energy to the tribe.\\\\n\\\\nAs Ula took her last breath, she whispered to Kade, \\\\\\\"May you grow up to be a fierce and proud caveman, just like your father.\\\\\\\" Ula's legacy lived on through her son, and her tribe honored her memory by carving her name into the walls of the cave. The story of Ula, the heavily pregnant cavewoman who defied death to give birth to Kade, became a legend that would be passed down through the generations.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56609,\n        \"samples\": [\n          \"[\\\"Unfortunately, I do not have enough context to provide specific details about \\\\\\\"mobility123\\\\\\\" in New Jersey. Mobility123 is not a term I am familiar with. To provide more useful information, it would be helpful if you could clarify what kind of service, company, or product mobility123 refers to, as well as any additional details about what you would like to know in relation to New Jersey. Please provide some more context and details so that I can try to assist. Let me know if you can share more information!\\\"]\",\n          \"[\\\"Abby, Amber, Amra, Arin, Arna, Ashy, Bari, Bett, Brix, Bryn, Brin, Brynne, Ciri, Cyrn, Ebby, Ebri, Elbr, Elmry, Embr, Raby, Reba\\\"]\",\n          \"[\\\"It's great that your child is considering how to communicate with her friends in a way that doesn't upset them. Here are some tips that may help:\\\\n\\\\n1. Listen actively: Encourage your child to listen to her friends without interrupting or judging them. This means paying attention to what they're saying, asking questions to clarify their thoughts, and acknowledging their feelings.\\\\n2. Use kind words: Remind your child to use kind and respectful language when talking to her friends. This means avoiding hurtful words or tone, and being mindful of how her words may be perceived by others.\\\\n3. Be empathetic: Encourage your child to try to see things from her friends' perspective and to understand their feelings and needs. This means putting herself in their shoes and considering how they might be feeling.\\\\n4. Avoid gossip: Remind your child that gossiping about her friends can be hurtful and damaging to their relationships. Encourage her to avoid talking about her friends behind their backs and to speak to them directly if she has concerns.\\\\n5. Be honest: Remind your child that honesty is always the best policy, even if it's difficult to hear. Encourage her to be open and truthful with her friends, but also to be gentle and considerate in how she delivers her message.\\\\n\\\\nBy following these tips, your child can learn how to communicate effectively with her friends without upsetting them.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_tie\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cmrX4u4Cim5",
        "outputId": "04efdc2d-70c9-43cb-bf65-3596ab185dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"27 apples\"]\n",
            "[\"As an AI, I don't have personal beliefs or opinions. However, I can tell you that the question of gender quotas in managerial positions is a complex one and positions can vary. Advocates argue that such measures can help correct historical imbalances, promote diversity, and may lead to better decision-making. Critics may argue that positions should be based purely on merit, and that quotas could potentially lead to tokenism or unqualified candidates being promoted. Morality can be subjective and differs from person to person based on their personal beliefs, cultural background, and values. It's a topic with valid arguments on both sides, and it's up to each individual or organization to decide what they believe is right.\",\"As an AI, I don't eat, so I don't have personal preferences. But, in the world of pizza, the pineapple topping is a hotly debated topic! Some people love the sweet and savory mix it brings to a pizza, a flavor combination made famous by the Hawaiian pizza. Others firmly believe that the sweetness of the fruit has no place on a pizza. It's a pizza puzzle that might never be solved. So, whether pineapple belongs on a pizza or not, it truly depends on your taste buds!\"]\n"
          ]
        }
      ],
      "source": [
        "def assign_label(row):\n",
        "    if row['winner_tie'] == 1:\n",
        "        return 1, 1, row['response_a'], row['response_b']\n",
        "    elif row['winner_model_a'] == 1:\n",
        "        return 2, 0, row['response_a'], row['response_b']\n",
        "    elif row['winner_model_b'] == 1:\n",
        "        return 0, 2, row['response_a'], row['response_b']\n",
        "\n",
        "# 'assign_label' 함수를 적용하여 'label'과 'response' 열 생성\n",
        "train_data['label_a'], train_data['label_b'], train_data['response_a'], train_data['response_b'] = zip(*train_data.apply(assign_label, axis=1))\n",
        "\n",
        "# 필요한 열만 선택 후 id와 response_a, response_b를 다루어 새로운 데이터프레임 생성\n",
        "response_a_df = train_data[['id', 'response_a', 'label_a']].rename(columns={'response_a': 'response', 'label_a': 'label'})\n",
        "response_b_df = train_data[['id', 'response_b', 'label_b']].rename(columns={'response_b': 'response', 'label_b': 'label'})\n",
        "train_data = pd.concat([response_a_df, response_b_df], ignore_index=True)\n",
        "print(train_data['response'][57476])\n",
        "print(train_data['response'][57477])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t7B2gNFDOwa",
        "outputId": "e8e83a85-a4d1-4515-b6bb-31a331e8284c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Bromadiolone is a rodenticide which is most often used in bait. It is a second generation anticoagulant that blocks the production of vitamin K1, which is essential for blood clotting. Without vitamin K1, the blood will not clot properly and the rat will bleed to death. Bromadiolone is effective at killing rats in a matter of hours and is often used in areas where rats are a problem, such as around homes, businesses, and farms.\"]\n",
            "[\"27 apples\"]\n",
            "====위까지 a, 아래부터 b====\n",
            "[\"As an AI, I don't have personal beliefs or opinions. However, I can tell you that the question of gender quotas in managerial positions is a complex one and positions can vary. Advocates argue that such measures can help correct historical imbalances, promote diversity, and may lead to better decision-making. Critics may argue that positions should be based purely on merit, and that quotas could potentially lead to tokenism or unqualified candidates being promoted. Morality can be subjective and differs from person to person based on their personal beliefs, cultural background, and values. It's a topic with valid arguments on both sides, and it's up to each individual or organization to decide what they believe is right.\",\"As an AI, I don't eat, so I don't have personal preferences. But, in the world of pizza, the pineapple topping is a hotly debated topic! Some people love the sweet and savory mix it brings to a pizza, a flavor combination made famous by the Hawaiian pizza. Others firmly believe that the sweetness of the fruit has no place on a pizza. It's a pizza puzzle that might never be solved. So, whether pineapple belongs on a pizza or not, it truly depends on your taste buds!\"]\n",
            "[\"A marriage license and a marriage certificate are two different legal documents that have separate purposes.\\n\\n1. Marriage License: A marriage license is a legal document that gives a couple permission to get married. It's usually obtained from local government or court officials before the wedding ceremony takes place. The couple is required to meet certain criteria, such as being of a certain age or not being closely related. Once the license is issued, there's often a waiting period before the marriage ceremony can take place. The marriage license has to be signed by the couple, their witnesses, and the officiant conducting the marriage ceremony, then returned to the license issuer for recording.\\n\\n2. Marriage Certificate: A marriage certificate, on the other hand, is a document that proves a marriage has legally taken place. It's issued after the marriage ceremony, once the signed marriage license has been returned and recorded. The marriage certificate includes details about the couple, like their names, the date and location of their wedding, and the names of their witnesses. This document serves as the official record of the marriage and is often needed for legal transactions like changing a name, adding a spouse to insurance, or proving marital status.\",\"In California, here are the general steps to obtain a marriage license and marriage certificate as quickly as possible:\\n\\n1. Marriage License:\\n\\n   - Both parties must appear together at one of the County Clerk\\u2019s offices.\\n   - Complete a marriage license application before arriving (available online in many counties).\\n   - Bring valid identification (driver's license, passport, etc.) to prove your identity and age.\\n   - In California, you do not need to be a resident, and there's no waiting period or blood test required.\\n   - Pay the marriage license fee. The fee varies by county but is usually between $35 and $100.\\n   - The marriage license is issued immediately and is valid for 90 days.\\n\\n2. Marriage Ceremony: \\n\\n   - Arrange to have a wedding ceremony within 90 days of receiving the license. This could be a civil ceremony performed at the County Clerk\\u2019s office or a private ceremony.\\n   - The person performing the ceremony must return the completed license to the County Recorder\\u2019s office within 10 days of the ceremony.\\n\\n3. Marriage Certificate: \\n\\n   - After the signed marriage license has been returned and registered by the County Recorder, it becomes a marriage certificate.\\n   - You can order copies of the certificate for an additional fee. Processing times can vary, but expedited service may be available for an extra fee.\\n\\nRemember, each county may have slightly different rules and fees, so it's best to check with your specific County Clerk\\u2019s office for the most accurate information.\",\"The marriage license in California is issued immediately when you apply in person and meet all the requirements, so theoretically, you could get married on the same day if you have an officiant ready to perform the ceremony.\\n\\nHowever, the marriage certificate, which is the official record of your marriage, is only issued after the signed marriage license is returned and recorded by the county. The person who performs your marriage ceremony has 10 days to return the license to the county recorder's office.\\n\\nSo, while you could technically get married (i.e., obtain a license and have a ceremony) within a day, receiving the official marriage certificate will take a little longer, depending on how quickly the signed license is returned and how long the county recorder's office takes to process it.\"]\n",
            "[\"Function calling is the process of invoking a function in a program. A function is a block of code that performs a specific task and can be reused multiple times in a program. Functions help to organize and modularize code, making it more readable and maintainable.\\n\\nTo call a function, you simply write the name of the function followed by parentheses () containing any arguments or parameters that the function requires. Here's an example:\\n```\\nfunction greet(name) {\\n  console.log(\\\"Hello, \\\" + name);\\n}\\n\\n\\/\\/ Call the greet function and pass in the argument \\\"Alice\\\"\\ngreet(\\\"Alice\\\");\\n```\\nIn the example above, the function `greet` takes one parameter, `name`, which is used inside the function to print a greeting message. To call the function, we write the name of the function (`greet`) followed by parentheses containing the argument `\\\"Alice\\\"`. When the function is called, the argument `\\\"Alice\\\"` is passed to the function, where it is assigned to the `name` parameter. The function then uses the `name` parameter to print the greeting message `\\\"Hello, Alice\\\"`.\\n\\nFunctions can also return values, which can be assigned to variables or used in expressions. For example:\\n```\\nfunction addNumbers(a, b) {\\n  return a + b;\\n}\\n\\n\\/\\/ Call the addNumbers function and assign the result to the variable sum\\nvar sum = addNumbers(3, 5);\\nconsole.log(sum); \\/\\/ Output: 8\\n```\\nIn the example above, the function `addNumbers` takes two parameters, `a` and `b`, adds them together, and returns the result. To call the function, we write the name of the function (`addNumbers`) followed by parentheses containing the arguments `3` and `5`. The function calculates the sum of the two arguments (`3 + 5 = 8`) and returns the result (`8`). We then assign the result to the variable `sum` and print it to the console.\"]\n"
          ]
        }
      ],
      "source": [
        "print(train_data['response'][57475])\n",
        "print(train_data['response'][57476])\n",
        "print('====위까지 a, 아래부터 b====')\n",
        "print(train_data['response'][57477])\n",
        "print(train_data['response'][57478])\n",
        "print(train_data['response'][57479])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbW-pVuDzT_j"
      },
      "source": [
        "## 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jl6rmThvBqr7"
      },
      "outputs": [],
      "source": [
        "train_data = datasets.Dataset.from_pandas(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B50iJNsX042F"
      },
      "source": [
        "changed in 3 = nltk!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2Uy-OrL9TiP",
        "outputId": "5cd06f66-db86-4bc9-d2a5-54e4174939ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx9iO4pv9nL0",
        "outputId": "1b970401-8628-4124-b4b5-16ea9ccd9613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6U4pMMkNxAM"
      },
      "source": [
        "자 어근만 추출하는 것추가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Sef8xnhmzVYn"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# NLTK의 WordNetLemmatizer 및 불용어 목록 로드\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokenizer = word_tokenize\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def nltk_tokenize_example(example, max_length):\n",
        "    # 문장을 토큰화\n",
        "    tokens = tokenizer(example[\"response\"])[:max_length]\n",
        "\n",
        "    # 불용어 제거 및 토큰들을 소문자로 변환\n",
        "    tokens = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
        "\n",
        "    # 토큰들을 원형으로 변환 #\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    length = len(tokens)\n",
        "    return {\"tokens\": tokens, \"length\": length}\n",
        "\n",
        "max_length = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOArzQR5O5gW",
        "outputId": "797530b3-9f77-46a9-cac6-ce0897076576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3d95e1e4e6b74b86b951e522020d72d5",
            "09f31b2ab63243148995ed95cc6083d3",
            "b5e0186db7234673bf3a226abaade31c",
            "8795a8f081714d4e8abf646d3b5322d2",
            "bbc0a43fb3de4e6db08434284105b348",
            "0851f09c1dd34f59be78b7ea4afbec4a",
            "2d242b60dc2b422197e3a495a6b68ebd",
            "5345cc9e70de43a3909913a907edc2f8",
            "366ef48b605542df91323b11d7d1b377",
            "102055a1e03a4b2ebe52e7e231152168",
            "db78dd372baf4d52b519ba3dbfe2c5eb"
          ]
        },
        "id": "lQiI4b7oFFOG",
        "outputId": "84c18653-cd6f-421c-9e0d-95c247ceeae1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/114954 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d95e1e4e6b74b86b951e522020d72d5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data = train_data.map(\n",
        "    nltk_tokenize_example, fn_kwargs={\"max_length\": max_length}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GYtbFR-Q8GZ4"
      },
      "outputs": [],
      "source": [
        "test_size = 0.25\n",
        "\n",
        "train_valid_data = train_data.train_test_split(test_size=test_size)\n",
        "train_data = train_valid_data[\"train\"]\n",
        "valid_data = train_valid_data[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMH2nMESFYg_",
        "outputId": "1befff94-8e9b-4576-8436-b4ae19907a36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86215, 28739)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(train_data), len(valid_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xw1rjWXHWES"
      },
      "source": [
        "## Vocab 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdsy7Lztzded",
        "outputId": "de130b3e-a579-4485-acdd-45030a681497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "min_freq = 2\n",
        "special_tokens = [\"<unk>\", \"<pad>\"]\n",
        "from torchtext.vocab import Vocab\n",
        "vocab = torchtext.vocab.build_vocab_from_iterator(\n",
        "    train_data[\"tokens\"],\n",
        "    min_freq=min_freq,\n",
        "    specials=special_tokens,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6ciWHwGFgVA",
        "outputId": "206e93dd-013b-4f24-d959-8598cc4bc61e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "212994"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCzCCtOMFj8f",
        "outputId": "251f67be-417f-4f31-95b9-25d40a9e19d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', ',', '.', \"''\", ':', '*', ')', '(', '``']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "vocab.get_itos()[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3cHX_z-uFmNQ"
      },
      "outputs": [],
      "source": [
        "unk_index = vocab[\"<unk>\"]\n",
        "pad_index = vocab[\"<pad>\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "almziavEHZMj"
      },
      "source": [
        "## 숫자화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "S--57U-uGqNj"
      },
      "outputs": [],
      "source": [
        "vocab.set_default_index(unk_index) #이거 없으면 numericalize 안돌아감 ;;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1WSzQNYrzgPr"
      },
      "outputs": [],
      "source": [
        "#여기서 글자를 숫자로 만드는구나...\n",
        "def numericalize(example, vocab):\n",
        "    ids = vocab.lookup_indices(example[\"tokens\"])\n",
        "    return {\"ids\": ids}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d54030d91420416d963d7eecab0045e3",
            "9bb97c10a5794b419298db4fc9dec1bf",
            "2f9a3e4e86314c3fabf95cc5a9efb77a",
            "7b8dc07f8fd142249d1b21acc5deba67",
            "4c620fdeb24b48da928b4002932578fa",
            "6b2eed170be844c6931faaebe644fe95",
            "18ec2d5364c94808a1a801ffa3cdc264",
            "6c5a8a1466424158b3da504669214e18",
            "3b80008febab4b34833184f85fd25632",
            "1b20f23ca4f7453b947dffb02ac95430",
            "d7f2314b78c14e8a8857b5a195dca16b",
            "e2f1a796037c4578b82dbf15aafc50d6",
            "631542cba2394585a8bdb7be3c37aed3",
            "b823b1d88fa34f6799aee1983a80fe6f",
            "4c2864d353f24ec0996e4c8124a76f5b",
            "11795cf7fdd34aae812be2a8cabe27a5",
            "c3f33efa0b2e48d0a211a97d63b840be",
            "f7496371b63d4d539a93f88e8a3aebd3",
            "4a5aacba9b264e1a88dd3ade0b52151d",
            "0b5ced88e9164fe3953977fac6b0e4ff",
            "4b03c349c67c418982537bc859cb963c",
            "6bf39107a2ce4b52b271ad01983ebd5c"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "rrLPz5NcGTcS",
        "outputId": "32abbc03-cc65-411b-ce06-b8351621e4c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/86215 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d54030d91420416d963d7eecab0045e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/28739 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2f1a796037c4578b82dbf15aafc50d6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data = train_data.map(numericalize, fn_kwargs={\"vocab\": vocab})\n",
        "valid_data = valid_data.map(numericalize, fn_kwargs={\"vocab\": vocab})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e2TgOxvHcgz"
      },
      "source": [
        "## 토치화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YX5S9NoRG4ZX"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", 'length'])\n",
        "valid_data = valid_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", 'length'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "N-2RB8GFSEdV"
      },
      "outputs": [],
      "source": [
        "def get_collate_fn(pad_index):\n",
        "    def collate_fn(batch):\n",
        "        batch_ids = [i[\"ids\"] for i in batch]\n",
        "        batch_ids = nn.utils.rnn.pad_sequence(\n",
        "            batch_ids, padding_value=pad_index, batch_first=True\n",
        "        )\n",
        "        batch_length = [i[\"length\"] for i in batch]\n",
        "        batch_length = torch.stack(batch_length)\n",
        "        batch_label = [i[\"label\"] for i in batch]\n",
        "        batch_label = torch.stack(batch_label)\n",
        "        batch = {\"ids\": batch_ids, \"length\": batch_length, \"label\": batch_label}\n",
        "        return batch\n",
        "\n",
        "    return collate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VuIrfNAn0BxQ"
      },
      "outputs": [],
      "source": [
        "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
        "    collate_fn = get_collate_fn(pad_index)\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        shuffle=shuffle,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "a7bYyfSE0IvW"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
        "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt4n_py1qgTM",
        "outputId": "cbefe12b-5c43-4cc7-bfd6-cccdfd80b032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.840B.300d.zip: 2.18GB [06:50, 5.30MB/s]                            \n",
            "100%|█████████▉| 2196016/2196017 [03:59<00:00, 9153.12it/s]\n"
          ]
        }
      ],
      "source": [
        "vectors = torchtext.vocab.GloVe()\n",
        "pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KXCr7J2Hdpc"
      },
      "source": [
        "# 모델! LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "F91yKcW20qVG"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        embedding_dim,\n",
        "        hidden_dim,\n",
        "        output_dim,\n",
        "        additional_linear_dim,\n",
        "        n_layers,\n",
        "        bidirectional,\n",
        "        dropout_rate,\n",
        "        pad_index,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            n_layers,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout_rate,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.fc1 = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, additional_linear_dim)\n",
        "        self.fc2 = nn.Linear(additional_linear_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.relu = nn.ReLU()  # ReLU 활성화 함수\n",
        "\n",
        "    def forward(self, ids, length):\n",
        "        embedded = self.dropout(self.embedding(ids))\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
        "            embedded, length, batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        output, output_length = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        if self.lstm.bidirectional:\n",
        "            hidden = self.dropout(torch.cat([hidden[-1], hidden[-2]], dim=-1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1])\n",
        "        hidden = self.relu(hidden)  # ReLU 활성화 함수 적용\n",
        "        hidden = self.fc1(hidden)\n",
        "        hidden = self.dropout(hidden)\n",
        "        prediction = self.fc2(hidden)\n",
        "        prediction = F.softmax(prediction, dim=-1)\n",
        "        return prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCnUh-zmNzzV"
      },
      "source": [
        "레이어 늘리고 차원도 늘림"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "l7_8hRpt-rea"
      },
      "outputs": [],
      "source": [
        "# 모델 초기화\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 300\n",
        "hidden_dim = 128\n",
        "output_dim = len(train_data.unique(\"label\"))\n",
        "additional_linear_dim = 15\n",
        "n_layers = 6\n",
        "bidirectional = True\n",
        "dropout_rate = 0.5\n",
        "pad_index = 0  # 예시로 0으로 설정\n",
        "lstm_model = LSTM(\n",
        "    vocab_size,\n",
        "    embedding_dim,\n",
        "    hidden_dim,\n",
        "    output_dim,\n",
        "    additional_linear_dim,\n",
        "    n_layers,\n",
        "    bidirectional,\n",
        "    dropout_rate,\n",
        "    pad_index,  # pad_index 제공\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YycQJJxK-9Da",
        "outputId": "d89f255c-edfd-4582-c9da-91a84d5b769b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 66,318,743 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f\"The model has {count_parameters(lstm_model):,} trainable parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "yREd-NRj-_tu"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "        nn.init.zeros_(m.bias)\n",
        "    elif isinstance(m, nn.LSTM):\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"bias\" in name:\n",
        "                nn.init.zeros_(param)\n",
        "            elif \"weight\" in name:\n",
        "                nn.init.orthogonal_(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZYb6Xmp_Buo",
        "outputId": "10d17655-c066-41a8-a25a-9f4e0314120c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (embedding): Embedding(212994, 300, padding_idx=0)\n",
              "  (lstm): LSTM(300, 128, num_layers=6, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (fc1): Linear(in_features=256, out_features=15, bias=True)\n",
              "  (fc2): Linear(in_features=15, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "lstm_model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "YkZjTN2U_Hbt"
      },
      "outputs": [],
      "source": [
        "lstm_model.embedding.weight.data = pretrained_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "zh2J900Q_IoT"
      },
      "outputs": [],
      "source": [
        "lr = 5e-4\n",
        "\n",
        "optimizer = optim.SGD(lstm_model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RenQxeaB_Ks2",
        "outputId": "d2640653-b358-467c-ab9f-98a1d0684cee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# cuda 사용함\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "LFPi2AUw_L6u"
      },
      "outputs": [],
      "source": [
        "lstm_model = lstm_model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "uR-QfgSXq4aq"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(prediction, label):\n",
        "    batch_size, _ = prediction.shape\n",
        "    predicted_classes = prediction.argmax(dim=-1)\n",
        "    correct_predictions = predicted_classes.eq(label).sum()\n",
        "    accuracy = correct_predictions / batch_size\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "uIYw8WBk_Ndr"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    epoch_losses = []\n",
        "    epoch_accs = []\n",
        "    for batch in tqdm.tqdm(dataloader, desc=\"training...\"):\n",
        "        ids = batch[\"ids\"].to(device)\n",
        "        length = batch[\"length\"]\n",
        "        label = batch[\"label\"].to(device)\n",
        "        prediction = model(ids, length)\n",
        "        loss = criterion(prediction, label)\n",
        "        accuracy = get_accuracy(prediction, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_losses.append(loss.item())\n",
        "        epoch_accs.append(accuracy.item())\n",
        "    return np.mean(epoch_losses), np.mean(epoch_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "SPdp50Te_Ot4"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader, model, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_losses = []\n",
        "    epoch_accs = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm.tqdm(dataloader, desc=\"evaluating...\"):\n",
        "            ids = batch[\"ids\"].to(device)\n",
        "            length = batch[\"length\"]\n",
        "            label = batch[\"label\"].to(device)\n",
        "            prediction = model(ids, length)\n",
        "            loss = criterion(prediction, label)\n",
        "            accuracy = get_accuracy(prediction, label)\n",
        "            epoch_losses.append(loss.item())\n",
        "            epoch_accs.append(accuracy.item())\n",
        "    return np.mean(epoch_losses), np.mean(epoch_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsyt_eXVq8hw"
      },
      "source": [
        "#LSTM 학습 & Val 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWVOJIt7gSke",
        "outputId": "04afcf22-b951-4e82-9305-48a3a1fdcf1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (embedding): Embedding(212994, 300, padding_idx=0)\n",
              "  (lstm): LSTM(300, 128, num_layers=6, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (fc1): Linear(in_features=256, out_features=15, bias=True)\n",
              "  (fc2): Linear(in_features=15, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "lstm_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Ktc1uQSpSUdE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "468860dd-34f9-4620-bb41-89cb12544ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 169/169 [02:02<00:00,  1.38it/s]\n",
            "evaluating...: 100%|██████████| 57/57 [00:12<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\n",
            "train_loss: 1.099, train_acc: 0.342\n",
            "valid_loss: 1.099, valid_acc: 0.347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...:  30%|██▉       | 50/169 [00:37<01:28,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-e4e006c75b49>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     train_loss, train_acc = train(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     )\n",
            "\u001b[0;32m<ipython-input-67-e8c6635af5e6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mepoch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "n_epochs = 10\n",
        "best_valid_loss = float(\"inf\")\n",
        "\n",
        "metrics = collections.defaultdict(list)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train(\n",
        "        train_data_loader, lstm_model, criterion, optimizer, device\n",
        "    )\n",
        "    valid_loss, valid_acc = evaluate(valid_data_loader, lstm_model, criterion, device)\n",
        "    metrics[\"train_losses\"].append(train_loss)\n",
        "    metrics[\"train_accs\"].append(train_acc)\n",
        "    metrics[\"valid_losses\"].append(valid_loss)\n",
        "    metrics[\"valid_accs\"].append(valid_acc)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(lstm_model.state_dict(), \"base_lstm.pt\")\n",
        "    print(f\"epoch: {epoch}\")\n",
        "    print(f\"train_loss: {train_loss:.3f}, train_acc: {train_acc:.3f}\")\n",
        "    print(f\"valid_loss: {valid_loss:.3f}, valid_acc: {valid_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PMhrBFL_Tuu"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 6))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(metrics[\"train_losses\"], label=\"train loss\")\n",
        "ax.plot(metrics[\"valid_losses\"], label=\"valid loss\")\n",
        "ax.set_xlabel(\"epoch\")\n",
        "ax.set_ylabel(\"loss\")\n",
        "ax.set_xticks(range(n_epochs))\n",
        "ax.legend()\n",
        "ax.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ht8CdVQY_Wfj"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 6))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(metrics[\"train_accs\"], label=\"train accuracy\")\n",
        "ax.plot(metrics[\"valid_accs\"], label=\"valid accuracy\")\n",
        "ax.set_xlabel(\"epoch\")\n",
        "ax.set_ylabel(\"loss\")\n",
        "ax.set_xticks(range(n_epochs))\n",
        "ax.legend()\n",
        "ax.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fep6UwwUPoov"
      },
      "outputs": [],
      "source": [
        "# Given values\n",
        "train_losses = [1.092, 1.080, 1.061, 1.031, 1.002, 0.974, 0.948, 0.924, 0.902, 0.883]\n",
        "valid_losses = [1.084, 1.080, 1.077, 1.074, 1.084, 1.087, 1.101, 1.108, 1.111, 1.116]\n",
        "train_accs = [0.365, 0.395, 0.430, 0.472, 0.511, 0.548, 0.579, 0.608, 0.634, 0.655]\n",
        "valid_accs = [0.391, 0.397, 0.404, 0.407, 0.400, 0.407, 0.408, 0.406, 0.404, 0.404]\n",
        "\n",
        "# Calculate the averages\n",
        "avg_train_loss = np.mean(train_losses)\n",
        "avg_valid_loss = np.mean(valid_losses)\n",
        "avg_train_acc = np.mean(train_accs)\n",
        "avg_valid_acc = np.mean(valid_accs)\n",
        "\n",
        "# Print the results\n",
        "print(f'Average Training Loss: {avg_train_loss:.4f}')\n",
        "print(f'Average Validation Loss: {avg_valid_loss:.4f}')\n",
        "print(f'Average Training Accuracy: {avg_train_acc:.4f}')\n",
        "print(f'Average Validation Accuracy: {avg_valid_acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCewtyaRzVGY"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5gTN7ql8BhQ"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOxDm/FOhI/3di5OdPnqH4D",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3d95e1e4e6b74b86b951e522020d72d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09f31b2ab63243148995ed95cc6083d3",
              "IPY_MODEL_b5e0186db7234673bf3a226abaade31c",
              "IPY_MODEL_8795a8f081714d4e8abf646d3b5322d2"
            ],
            "layout": "IPY_MODEL_bbc0a43fb3de4e6db08434284105b348"
          }
        },
        "09f31b2ab63243148995ed95cc6083d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0851f09c1dd34f59be78b7ea4afbec4a",
            "placeholder": "​",
            "style": "IPY_MODEL_2d242b60dc2b422197e3a495a6b68ebd",
            "value": "Map: 100%"
          }
        },
        "b5e0186db7234673bf3a226abaade31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5345cc9e70de43a3909913a907edc2f8",
            "max": 114954,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_366ef48b605542df91323b11d7d1b377",
            "value": 114954
          }
        },
        "8795a8f081714d4e8abf646d3b5322d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_102055a1e03a4b2ebe52e7e231152168",
            "placeholder": "​",
            "style": "IPY_MODEL_db78dd372baf4d52b519ba3dbfe2c5eb",
            "value": " 114954/114954 [04:02&lt;00:00, 491.75 examples/s]"
          }
        },
        "bbc0a43fb3de4e6db08434284105b348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0851f09c1dd34f59be78b7ea4afbec4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d242b60dc2b422197e3a495a6b68ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5345cc9e70de43a3909913a907edc2f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "366ef48b605542df91323b11d7d1b377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "102055a1e03a4b2ebe52e7e231152168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db78dd372baf4d52b519ba3dbfe2c5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d54030d91420416d963d7eecab0045e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bb97c10a5794b419298db4fc9dec1bf",
              "IPY_MODEL_2f9a3e4e86314c3fabf95cc5a9efb77a",
              "IPY_MODEL_7b8dc07f8fd142249d1b21acc5deba67"
            ],
            "layout": "IPY_MODEL_4c620fdeb24b48da928b4002932578fa"
          }
        },
        "9bb97c10a5794b419298db4fc9dec1bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b2eed170be844c6931faaebe644fe95",
            "placeholder": "​",
            "style": "IPY_MODEL_18ec2d5364c94808a1a801ffa3cdc264",
            "value": "Map: 100%"
          }
        },
        "2f9a3e4e86314c3fabf95cc5a9efb77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c5a8a1466424158b3da504669214e18",
            "max": 86215,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b80008febab4b34833184f85fd25632",
            "value": 86215
          }
        },
        "7b8dc07f8fd142249d1b21acc5deba67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b20f23ca4f7453b947dffb02ac95430",
            "placeholder": "​",
            "style": "IPY_MODEL_d7f2314b78c14e8a8857b5a195dca16b",
            "value": " 86215/86215 [00:28&lt;00:00, 2898.53 examples/s]"
          }
        },
        "4c620fdeb24b48da928b4002932578fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b2eed170be844c6931faaebe644fe95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ec2d5364c94808a1a801ffa3cdc264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c5a8a1466424158b3da504669214e18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b80008febab4b34833184f85fd25632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b20f23ca4f7453b947dffb02ac95430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7f2314b78c14e8a8857b5a195dca16b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2f1a796037c4578b82dbf15aafc50d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_631542cba2394585a8bdb7be3c37aed3",
              "IPY_MODEL_b823b1d88fa34f6799aee1983a80fe6f",
              "IPY_MODEL_4c2864d353f24ec0996e4c8124a76f5b"
            ],
            "layout": "IPY_MODEL_11795cf7fdd34aae812be2a8cabe27a5"
          }
        },
        "631542cba2394585a8bdb7be3c37aed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3f33efa0b2e48d0a211a97d63b840be",
            "placeholder": "​",
            "style": "IPY_MODEL_f7496371b63d4d539a93f88e8a3aebd3",
            "value": "Map: 100%"
          }
        },
        "b823b1d88fa34f6799aee1983a80fe6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a5aacba9b264e1a88dd3ade0b52151d",
            "max": 28739,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b5ced88e9164fe3953977fac6b0e4ff",
            "value": 28739
          }
        },
        "4c2864d353f24ec0996e4c8124a76f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b03c349c67c418982537bc859cb963c",
            "placeholder": "​",
            "style": "IPY_MODEL_6bf39107a2ce4b52b271ad01983ebd5c",
            "value": " 28739/28739 [00:09&lt;00:00, 2906.78 examples/s]"
          }
        },
        "11795cf7fdd34aae812be2a8cabe27a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3f33efa0b2e48d0a211a97d63b840be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7496371b63d4d539a93f88e8a3aebd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a5aacba9b264e1a88dd3ade0b52151d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b5ced88e9164fe3953977fac6b0e4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b03c349c67c418982537bc859cb963c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bf39107a2ce4b52b271ad01983ebd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}